{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import requests\n",
    "from IPython.display import HTML, display\n",
    "from pandas import DataFrame\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import poisson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.jp-OutputArea-output pre {white-space: pre;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Avoid line breaks by Jupyter (following https://stackoverflow.com/a/70433850/7395592)\n",
    "\n",
    "display(HTML(\"<style>div.jp-OutputArea-output pre {white-space: pre;}</style>\"))\n",
    "\n",
    "# Avoid premature line breaks by Numpy and show all array entries\n",
    "\n",
    "np.set_printoptions(linewidth=np.inf, threshold=np.inf)\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nested_value(d, keys, default=None):\n",
    "    for key in keys:\n",
    "        if isinstance(d, dict):\n",
    "            d = d.get(key, default)\n",
    "        else:\n",
    "            return default\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_match_data(uefa_config: dict, limit: int = 100):\n",
    "\n",
    "    competition_id = uefa_config[\"competition_id\"]\n",
    "    season_years = uefa_config[\"season_years\"]\n",
    "\n",
    "    data = []\n",
    "    for season_year in season_years:\n",
    "\n",
    "        params = {\"limit\": limit}\n",
    "        if competition_id:\n",
    "            params.update({\"competitionId\": competition_id})\n",
    "        if season_year:\n",
    "            params.update({\"seasonYear\": season_year})\n",
    "\n",
    "        data_season = []\n",
    "        for offset in range(0, limit * 5, limit):\n",
    "\n",
    "            params_iter = {\"offset\": offset}\n",
    "            _params = params | params_iter\n",
    "            response = requests.get(\n",
    "                uefa[\"url_matches\"], params=_params, headers=headers\n",
    "            )\n",
    "\n",
    "            data_iter = response.json()\n",
    "            if not data_iter:\n",
    "                break\n",
    "\n",
    "            data_season += data_iter\n",
    "\n",
    "        data += data_season\n",
    "\n",
    "    data_reduced = []\n",
    "    for record in data:\n",
    "\n",
    "        datetime_str = get_nested_value(record, [\"kickOffTime\", \"dateTime\"])\n",
    "        datetime_offset_str = get_nested_value(\n",
    "            record, [\"kickOffTime\", \"utcOffsetInHours\"]\n",
    "        )\n",
    "        if datetime_str is None:\n",
    "            is_completed = False\n",
    "            parsed_date = None\n",
    "        else:\n",
    "            parsed_date = datetime.fromisoformat(\n",
    "                datetime_str.replace(\"Z\", \"+00:00\")\n",
    "            ) + timedelta(hours=datetime_offset_str)\n",
    "            current_date = datetime.now(timezone.utc)\n",
    "            is_completed = parsed_date < current_date\n",
    "\n",
    "        home_score_total = get_nested_value(record, [\"score\", \"total\", \"home\"])\n",
    "        away_score_total = get_nested_value(record, [\"score\", \"total\", \"away\"])\n",
    "\n",
    "        home_team_code = get_nested_value(record, [\"homeTeam\", \"teamCode\"])\n",
    "        away_team_code = get_nested_value(record, [\"awayTeam\", \"teamCode\"])\n",
    "\n",
    "        score_summary = (\n",
    "            None\n",
    "            if home_score_total is None\n",
    "            else \" \".join(\n",
    "                [\n",
    "                    home_team_code,\n",
    "                    str(home_score_total),\n",
    "                    \"-\",\n",
    "                    str(away_score_total),\n",
    "                    away_team_code,\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        result = (\n",
    "            None\n",
    "            if home_score_total is None\n",
    "            else (\n",
    "                \"H\"\n",
    "                if home_score_total > away_score_total\n",
    "                else \"A\" if home_score_total < away_score_total else \"D\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        status = get_nested_value(record, [\"round\", \"status\"])\n",
    "        if status == \"UPCOMING\":\n",
    "            continue\n",
    "\n",
    "        record_reduced = {\n",
    "            \"id\": record[\"id\"],\n",
    "            \"season_year\": record[\"seasonYear\"],\n",
    "            \"date\": parsed_date,\n",
    "            # Context\n",
    "            \"phase\": get_nested_value(record, [\"round\", \"phase\"]),\n",
    "            \"mode\": get_nested_value(record, [\"round\", \"mode\"]),\n",
    "            \"status\": status,\n",
    "            \"is_completed\": is_completed,\n",
    "            # Home Team\n",
    "            \"home_team\": get_nested_value(record, [\"homeTeam\", \"id\"]),\n",
    "            \"home_team_name\": get_nested_value(\n",
    "                record, [\"homeTeam\", \"internationalName\"]\n",
    "            ),\n",
    "            \"home_team_code\": home_team_code,\n",
    "            \"home_score\": get_nested_value(record, [\"score\", \"regular\", \"home\"]),\n",
    "            \"home_score_total\": home_score_total,\n",
    "            # Away Team\n",
    "            \"away_team\": get_nested_value(record, [\"awayTeam\", \"id\"]),\n",
    "            \"away_team_name\": get_nested_value(\n",
    "                record, [\"awayTeam\", \"internationalName\"]\n",
    "            ),\n",
    "            \"away_team_code\": away_team_code,\n",
    "            \"away_score\": get_nested_value(record, [\"score\", \"regular\", \"away\"]),\n",
    "            \"away_score_total\": away_score_total,\n",
    "            # Score/Result\n",
    "            \"score\": score_summary,\n",
    "            \"result\": result,\n",
    "        }\n",
    "        data_reduced.append(record_reduced)\n",
    "\n",
    "    df = pd.DataFrame(data_reduced)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_match_data(df: DataFrame, year_min: int = 1996):\n",
    "\n",
    "    df = df.loc[df[\"season_year\"].apply(pd.to_numeric) >= year_min]\n",
    "    df = df.loc[df[\"is_completed\"]]\n",
    "    df = df.loc[df[\"home_score_total\"] >= 0]\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df[\"time_diff\"] = (max(df[\"date\"]) - df[\"date\"]).dt.days\n",
    "\n",
    "    df = df.drop([\"home_team\", \"away_team\"], axis=1)\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"home_score_total\": \"home_goals\",\n",
    "            \"away_score_total\": \"away_goals\",\n",
    "            \"home_team_name\": \"home_team\",\n",
    "            \"away_team_name\": \"away_team\",\n",
    "        }\n",
    "    )\n",
    "    df = df[\n",
    "        [\n",
    "            \"id\",\n",
    "            \"home_team\",\n",
    "            \"away_team\",\n",
    "            \"home_goals\",\n",
    "            \"away_goals\",\n",
    "            \"time_diff\",\n",
    "            \"date\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rho_correction(x, y, lambda_x, mu_y, rho):\n",
    "    result = np.ones_like(x)  # Initialize with ones\n",
    "\n",
    "    zero_zero_mask = (x == 0) & (y == 0)\n",
    "    zero_one_mask = (x == 0) & (y == 1)\n",
    "    one_zero_mask = (x == 1) & (y == 0)\n",
    "    one_one_mask = (x == 1) & (y == 1)\n",
    "\n",
    "    result[zero_zero_mask] = 1 - (lambda_x[zero_zero_mask] * mu_y[zero_zero_mask] * rho)\n",
    "    result[zero_one_mask] = 1 + (lambda_x[zero_one_mask] * rho)\n",
    "    result[one_zero_mask] = 1 + (mu_y[one_zero_mask] * rho)\n",
    "    result[one_one_mask] = 1 - rho\n",
    "\n",
    "    # Avoid log(0) and log(negative)\n",
    "    result = np.maximum(result, 1e-10)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_parameters(\n",
    "    dataset,\n",
    "    init_vals=None,\n",
    "    options={\"disp\": False, \"maxiter\": 500},\n",
    "    constraints=[{\"type\": \"eq\", \"fun\": lambda x: sum(x[:20]) - 20}],\n",
    "    **kwargs\n",
    "):\n",
    "    teams = np.sort(dataset[\"home_team\"].unique())\n",
    "    # check for no weirdness in dataset\n",
    "    away_teams = np.sort(dataset[\"away_team\"].unique())\n",
    "    if not np.array_equal(teams, away_teams):\n",
    "        raise ValueError(\"Something's not right\")\n",
    "    n_teams = len(teams)\n",
    "    if init_vals is None:\n",
    "        # random initialisation of model parameters\n",
    "        init_vals = np.concatenate(\n",
    "            (\n",
    "                np.random.uniform(0, 1, (n_teams)),  # attack strength\n",
    "                np.random.uniform(0, -1, (n_teams)),  # defence strength\n",
    "                np.array([0, 1.0]),  # rho (score correction), gamma (home advantage)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def dc_log_like_vectorized(\n",
    "        home_goals, away_goals, alpha_x, beta_x, alpha_y, beta_y, rho, gamma\n",
    "    ):\n",
    "        lambda_x = np.exp(alpha_x + beta_y + gamma)\n",
    "        mu_y = np.exp(alpha_y + beta_x)\n",
    "\n",
    "        rho_corr = rho_correction(home_goals, away_goals, lambda_x, mu_y, rho)\n",
    "        poisson_pmf_x = np.maximum(poisson.pmf(home_goals, lambda_x), 1e-10)\n",
    "        poisson_pmf_y = np.maximum(poisson.pmf(away_goals, mu_y), 1e-10)\n",
    "\n",
    "        return np.log(rho_corr) + np.log(poisson_pmf_x) + np.log(poisson_pmf_y)\n",
    "\n",
    "    def estimate_parameters(params):\n",
    "        score_coefs = dict(zip(teams, params[:n_teams]))\n",
    "        defend_coefs = dict(zip(teams, params[n_teams : (2 * n_teams)]))\n",
    "        rho, gamma = params[-2:]\n",
    "\n",
    "        home_goals = dataset[\"home_goals\"].values\n",
    "        away_goals = dataset[\"away_goals\"].values\n",
    "        alpha_x = dataset[\"home_team\"].map(score_coefs).values\n",
    "        beta_x = dataset[\"home_team\"].map(defend_coefs).values\n",
    "        alpha_y = dataset[\"away_team\"].map(score_coefs).values\n",
    "        beta_y = dataset[\"away_team\"].map(defend_coefs).values\n",
    "\n",
    "        log_likes = dc_log_like_vectorized(\n",
    "            home_goals, away_goals, alpha_x, beta_x, alpha_y, beta_y, rho, gamma\n",
    "        )\n",
    "        return -np.sum(log_likes)\n",
    "\n",
    "    opt_output = minimize(\n",
    "        estimate_parameters,\n",
    "        init_vals,\n",
    "        options=options,\n",
    "        constraints=constraints,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    return dict(\n",
    "        zip(\n",
    "            [\"attack_\" + team for team in teams]\n",
    "            + [\"defence_\" + team for team in teams]\n",
    "            + [\"rho\", \"home_adv\"],\n",
    "            opt_output.x,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_parameters_decay(\n",
    "    dataset,\n",
    "    xi=0.001,\n",
    "    init_vals=None,\n",
    "    options={\"disp\": True, \"maxiter\": 500},\n",
    "    constraints=[{\"type\": \"eq\", \"fun\": lambda x: sum(x[:20]) - 20}],\n",
    "    **kwargs\n",
    "):\n",
    "    teams = np.sort(dataset[\"home_team\"].unique())\n",
    "    # check for no weirdness in dataset\n",
    "    away_teams = np.sort(dataset[\"away_team\"].unique())\n",
    "    if not np.array_equal(teams, away_teams):\n",
    "        raise ValueError(\"Something's not right\")\n",
    "    n_teams = len(teams)\n",
    "    if init_vals is None:\n",
    "        # random initialisation of model parameters\n",
    "        init_vals = np.concatenate(\n",
    "            (\n",
    "                np.random.uniform(0, 1, (n_teams)),  # attack strength\n",
    "                np.random.uniform(0, -1, (n_teams)),  # defence strength\n",
    "                np.array([0, 1.0]),  # rho (score correction), gamma (home advantage)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def dc_log_like_decay_vectorized(\n",
    "        x, y, alpha_x, beta_x, alpha_y, beta_y, rho, gamma, t, xi\n",
    "    ):\n",
    "        lambda_x = np.exp(alpha_x + beta_y + gamma)\n",
    "        mu_y = np.exp(alpha_y + beta_x)\n",
    "\n",
    "        rho_corr = rho_correction(x, y, lambda_x, mu_y, rho)\n",
    "        poisson_pmf_x = np.maximum(poisson.pmf(x, lambda_x), 1e-10)\n",
    "        poisson_pmf_y = np.maximum(poisson.pmf(y, mu_y), 1e-10)\n",
    "\n",
    "        decay_factor = np.exp(-xi * t)\n",
    "        log_likes = decay_factor * (\n",
    "            np.log(rho_corr) + np.log(poisson_pmf_x) + np.log(poisson_pmf_y)\n",
    "        )\n",
    "        return log_likes\n",
    "\n",
    "    def estimate_parameters(params):\n",
    "        score_coefs = dict(zip(teams, params[:n_teams]))\n",
    "        defend_coefs = dict(zip(teams, params[n_teams : (2 * n_teams)]))\n",
    "        rho, gamma = params[-2:]\n",
    "\n",
    "        home_goals = dataset[\"home_goals\"].values\n",
    "        away_goals = dataset[\"away_goals\"].values\n",
    "        alpha_x = dataset[\"home_team\"].map(score_coefs).values\n",
    "        beta_x = dataset[\"home_team\"].map(defend_coefs).values\n",
    "        alpha_y = dataset[\"away_team\"].map(score_coefs).values\n",
    "        beta_y = dataset[\"away_team\"].map(defend_coefs).values\n",
    "\n",
    "        log_likes = dc_log_like_decay_vectorized(\n",
    "            home_goals, away_goals, alpha_x, beta_x, alpha_y, beta_y, rho, gamma, xi=xi\n",
    "        )\n",
    "        return -np.sum(log_likes)\n",
    "\n",
    "    opt_output = minimize(\n",
    "        estimate_parameters,\n",
    "        init_vals,\n",
    "        options=options,\n",
    "        constraints=constraints,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    return dict(\n",
    "        zip(\n",
    "            [\"attack_\" + team for team in teams]\n",
    "            + [\"defence_\" + team for team in teams]\n",
    "            + [\"rho\", \"home_adv\"],\n",
    "            opt_output.x,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_means(param_dict, home_team, away_team):\n",
    "    return [\n",
    "        np.exp(\n",
    "            param_dict[\"attack_\" + home_team]\n",
    "            + param_dict[\"defence_\" + away_team]\n",
    "            + param_dict[\"home_adv\"]\n",
    "        ),\n",
    "        np.exp(param_dict[\"defence_\" + home_team] + param_dict[\"attack_\" + away_team]),\n",
    "    ]\n",
    "\n",
    "\n",
    "def rho_correction_old(x, y, lambda_x, mu_y, rho):\n",
    "    if x == 0 and y == 0:\n",
    "        return 1 - (lambda_x * mu_y * rho)\n",
    "    elif x == 0 and y == 1:\n",
    "        return 1 + (lambda_x * rho)\n",
    "    elif x == 1 and y == 0:\n",
    "        return 1 + (mu_y * rho)\n",
    "    elif x == 1 and y == 1:\n",
    "        return 1 - rho\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "\n",
    "def dixon_coles_simulate_match(params_dict, home_team, away_team, max_goals=10):\n",
    "    team_avgs = calc_means(params_dict, home_team, away_team)\n",
    "    team_pred = [\n",
    "        [poisson.pmf(i, team_avg) for i in range(0, max_goals + 1)]\n",
    "        for team_avg in team_avgs\n",
    "    ]\n",
    "    output_matrix = np.outer(np.array(team_pred[0]), np.array(team_pred[1]))\n",
    "    correction_matrix = np.array(\n",
    "        [\n",
    "            [\n",
    "                rho_correction_old(\n",
    "                    home_goals,\n",
    "                    away_goals,\n",
    "                    team_avgs[0],\n",
    "                    team_avgs[1],\n",
    "                    params_dict[\"rho\"],\n",
    "                )\n",
    "                for away_goals in range(2)\n",
    "            ]\n",
    "            for home_goals in range(2)\n",
    "        ]\n",
    "    )\n",
    "    output_matrix[:2, :2] = output_matrix[:2, :2] * correction_matrix\n",
    "    return output_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_match(\n",
    "    params: dict,\n",
    "    home_team: str = \"England\",\n",
    "    away_team: str = \"Denmark\",\n",
    "    max_goals: int = 6,\n",
    "):\n",
    "    test_match = dixon_coles_simulate_match(\n",
    "        params, home_team, away_team, max_goals=max_goals\n",
    "    )\n",
    "\n",
    "\n",
    "    with np.printoptions(precision=3, suppress=True):\n",
    "        print(test_match)\n",
    "\n",
    "\n",
    "    predicted_score = np.unravel_index(np.argmax(test_match), test_match.shape)\n",
    "    print(predicted_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1x2_probs(match_score_matrix):\n",
    "    return dict(\n",
    "        {\n",
    "            \"H\": np.sum(np.tril(match_score_matrix, -1)),\n",
    "            \"A\": np.sum(np.triu(match_score_matrix, 1)),\n",
    "            \"D\": np.sum(np.diag(match_score_matrix)),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def build_temp_model(dataset, time_diff, xi=0.000, init_params=None):\n",
    "    test_dataset = dataset[\n",
    "        (\n",
    "            (dataset[\"time_diff\"] <= time_diff)\n",
    "            & (dataset[\"time_diff\"] >= (time_diff - 2))\n",
    "        )\n",
    "    ]\n",
    "    if len(test_dataset) == 0:\n",
    "        return 0\n",
    "    train_dataset = dataset[dataset[\"time_diff\"] > time_diff]\n",
    "    train_dataset[\"time_diff\"] = train_dataset[\"time_diff\"] - time_diff\n",
    "    params = solve_parameters_decay(train_dataset, xi=xi, init_vals=init_params)\n",
    "    predictive_score = sum(\n",
    "        [\n",
    "            np.log(\n",
    "                get_1x2_probs(\n",
    "                    dixon_coles_simulate_match(params, row.HomeTeam, row.AwayTeam)\n",
    "                )[row.FTR]\n",
    "            )\n",
    "            for row in test_dataset.itertuples()\n",
    "        ]\n",
    "    )\n",
    "    return predictive_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_match_data(\n",
    "    source_matches: DataFrame, params: dict, sim_date: datetime\n",
    "):\n",
    "    future_matches_ = source_matches.drop(\n",
    "        [\"is_completed\", \"home_score\", \"away_score\", \"home_team\", \"away_team\"], axis=1\n",
    "    )\n",
    "\n",
    "    future_matches_ = future_matches_.loc[future_matches_[\"date\"] >= sim_date]\n",
    "\n",
    "    future_matches_ = future_matches_.rename(\n",
    "        columns={\n",
    "            \"home_score_total\": \"home_goals\",\n",
    "            \"away_score_total\": \"away_goals\",\n",
    "            \"home_team_name\": \"home_team\",\n",
    "            \"away_team_name\": \"away_team\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    future_matches_[\"home_goalsActual\"] = future_matches_[\"home_goals\"]\n",
    "\n",
    "    future_matches_[\"away_goalsActual\"] = future_matches_[\"away_goals\"]\n",
    "\n",
    "    future_matches_ = future_matches_[\n",
    "        [\n",
    "            \"id\",\n",
    "            \"date\",\n",
    "            \"home_team\",\n",
    "            \"away_team\",\n",
    "            \"home_goals\",\n",
    "            \"away_goals\",\n",
    "            \"home_goalsActual\",\n",
    "            \"away_goalsActual\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    for index, row in future_matches_.iterrows():\n",
    "\n",
    "        prediction = dixon_coles_simulate_match(\n",
    "            params, row[\"home_team\"], row[\"away_team\"], max_goals=6\n",
    "        )\n",
    "\n",
    "        predicted_score = np.unravel_index(np.argmax(prediction), prediction.shape)\n",
    "\n",
    "        future_matches_.loc[index, \"home_goals\"] = predicted_score[0]\n",
    "\n",
    "        future_matches_.loc[index, \"away_goals\"] = predicted_score[1]\n",
    "\n",
    "        result = (\n",
    "            \"H\"\n",
    "            if predicted_score[0] > predicted_score[1]\n",
    "            else \"A\" if predicted_score[0] < predicted_score[1] else \"D\"\n",
    "        )\n",
    "\n",
    "        result_actual = (\n",
    "            \"\"\n",
    "            if pd.isnull(row[\"home_goalsActual\"])\n",
    "            else (\n",
    "                \"H\"\n",
    "                if row[\"home_goalsActual\"] > row[\"away_goalsActual\"]\n",
    "                else \"A\" if row[\"home_goalsActual\"] < row[\"away_goalsActual\"] else \"D\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        future_matches_.loc[index, \"Result\"] = result\n",
    "\n",
    "        future_matches_.loc[index, \"ResultActual\"] = result_actual\n",
    "\n",
    "        performance = 0\n",
    "\n",
    "        if not pd.isnull(row[\"home_goalsActual\"]):\n",
    "\n",
    "            if (\n",
    "                predicted_score[0] == row[\"home_goalsActual\"]\n",
    "                and predicted_score[1] == row[\"away_goalsActual\"]\n",
    "            ):\n",
    "\n",
    "                performance += 5\n",
    "\n",
    "            elif result == result_actual:\n",
    "\n",
    "                performance += 2\n",
    "\n",
    "        future_matches_.loc[index, \"ModelPerformance\"] = performance\n",
    "\n",
    "    future_matches_ = future_matches_[\n",
    "        [\n",
    "            \"id\",\n",
    "            \"date\",\n",
    "            \"home_team\",\n",
    "            \"away_team\",\n",
    "            \"home_goals\",\n",
    "            \"away_goals\",\n",
    "            \"Result\",\n",
    "            \"home_goalsActual\",\n",
    "            \"away_goalsActual\",\n",
    "            \"ResultActual\",\n",
    "            \"ModelPerformance\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    return future_matches_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions_to_csv(predicted_matches: DataFrame, sim_year_max:int, sim_year_min:int):\n",
    "    future_matches_ = predicted_matches\n",
    "    order_list = [\n",
    "        \"2036161\",\n",
    "        \"2036162\",\n",
    "        \"2036163\",\n",
    "        \"2036164\",\n",
    "        \"2036167\",\n",
    "        \"2036165\",\n",
    "        \"2036166\",\n",
    "        \"2036170\",\n",
    "        \"2036169\",\n",
    "        \"2036168\",\n",
    "        \"2036171\",\n",
    "        \"2036172\",\n",
    "        \"2036176\",\n",
    "        \"2036173\",\n",
    "        \"2036174\",\n",
    "        \"2036177\",\n",
    "        \"2036178\",\n",
    "        \"2036175\",\n",
    "        \"2036182\",\n",
    "        \"2036179\",\n",
    "        \"2036180\",\n",
    "        \"2036184\",\n",
    "        \"2036183\",\n",
    "        \"2036181\",\n",
    "        \"2036185\",\n",
    "        \"2036186\",\n",
    "        \"2036187\",\n",
    "        \"2036188\",\n",
    "        \"2036191\",\n",
    "        \"2036192\",\n",
    "        \"2036190\",\n",
    "        \"2036189\",\n",
    "        \"2036194\",\n",
    "        \"2036193\",\n",
    "        \"2036196\",\n",
    "        \"2036195\",\n",
    "    ]\n",
    "\n",
    "\n",
    "    future_matches_[\"id\"] = pd.Categorical(\n",
    "        future_matches_[\"id\"], categories=order_list, ordered=True\n",
    "    )\n",
    "\n",
    "\n",
    "    future_matches_ = future_matches_.sort_values(\"id\")\n",
    "\n",
    "    future_matches_.to_csv(\n",
    "        \"predictions\\\\euros2024_predictions_model\"\n",
    "        + str(sim_year_max)\n",
    "        + \"-\"\n",
    "        + str(sim_year_min)\n",
    "        + \".csv\",\n",
    "        index=False,\n",
    "        encoding=\"utf-8-sig\",\n",
    "        mode=\"w\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_column_in_csv(file_path, column_name):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        summed_value = df[column_name].sum()\n",
    "        return summed_value\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def total_possible_in_csv(file_path, column_name):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        total_possible = df[df[column_name] != \"\"][column_name].count()\n",
    "        return total_possible\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def display_model_performance():\n",
    "    # Specify the folder path containing CSV files\n",
    "    folder_path = \"predictions\"  # Replace with your folder path\n",
    "\n",
    "    # Initialize a list to store dictionaries of file summaries\n",
    "    file_summaries = []\n",
    "\n",
    "    # Iterate over files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            summed_value = sum_column_in_csv(file_path, \"ModelPerformance\")\n",
    "            total_possible = total_possible_in_csv(file_path, \"ResultActual\") * 5\n",
    "\n",
    "            file_summary = {\n",
    "                \"file_name\": file_name\n",
    "            }  # Initialize summary dictionary for the current file\n",
    "\n",
    "            if summed_value is not None:\n",
    "                file_summary[\"summed_value\"] = int(summed_value)\n",
    "\n",
    "            if total_possible is not None:\n",
    "                file_summary[\"total_possible\"] = total_possible\n",
    "\n",
    "            if summed_value is not None and total_possible is not None:\n",
    "                file_summary[\"percent\"] = round(summed_value / total_possible * 100, 1)\n",
    "\n",
    "            file_summaries.append(file_summary)  # Add summary dictionary to the list\n",
    "\n",
    "    # Print file summaries\n",
    "    for summary in file_summaries:\n",
    "        print(\n",
    "            f'File: {summary[\"file_name\"]}, Performance: {summary.get(\"summed_value\", \"N/A\")}, Total: {summary.get(\"total_possible\", \"N/A\")} ({summary.get(\"percent\", \"N/A\")}%)'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uefa_config(sim_year_max: int, sim_year_min: int):\n",
    "    uefa = {\n",
    "        \"competition_id\": 3,\n",
    "        \"url_competition\": \"https://comp.uefa.com/v2/competition-structure\",\n",
    "        \"url_matches\": \"https://match.uefa.com/v5/matches\",\n",
    "        \"url_teams\": \"https://comp.uefa.com/v2/teams\",\n",
    "        \"season_years\": range(sim_year_max, sim_year_min - 1, -4),\n",
    "    }\n",
    "    return uefa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_debug_start_time():\n",
    "    if not globals().get(\"start_time\"):\n",
    "        global start_time\n",
    "        start_time = time.time()\n",
    "\n",
    "    return start_time\n",
    "\n",
    "\n",
    "def get_debug_elapsed_time(start_time: float):\n",
    "    elapsed_time = time.time() - start_time\n",
    "    formatted_time = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n",
    "    return formatted_time\n",
    "\n",
    "\n",
    "def print_debug_string(string: str):\n",
    "    print(f\"{get_debug_elapsed_time(get_debug_start_time())}    {string}\")\n",
    "\n",
    "\n",
    "def print_debug(string: str, lines_before: int = 0, lines_after: int = 0):\n",
    "    spacer = \"==================================================\"\n",
    "    for _ in itertools.repeat(None, lines_before):\n",
    "        print_debug_string(spacer)\n",
    "    print_debug_string(string)\n",
    "    for _ in itertools.repeat(None, lines_after):\n",
    "        print_debug_string(spacer)\n",
    "\n",
    "\n",
    "def end_debug():\n",
    "    global start_time\n",
    "    del start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_date = datetime.fromisoformat(\"2024-06-14\").replace(tzinfo=pytz.UTC)\n",
    "sim_year_max = 2024\n",
    "sim_year_mins = [1996, 2000, 2004, 2008, 2012, 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00:00: ==================================================\n",
      "00:00:00: Downloading data from https://match.uefa.com/v5/matches\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m uefa \u001b[38;5;241m=\u001b[39m get_uefa_config(sim_year_max, \u001b[38;5;28mmin\u001b[39m(sim_year_mins))\n\u001b[0;32m      2\u001b[0m print_debug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muefa[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl_matches\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m match_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_all_match_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43muefa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m print_debug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[25], line 20\u001b[0m, in \u001b[0;36mget_all_match_data\u001b[1;34m(uefa_config, limit)\u001b[0m\n\u001b[0;32m     18\u001b[0m params_iter \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffset\u001b[39m\u001b[38;5;124m\"\u001b[39m: offset}\n\u001b[0;32m     19\u001b[0m _params \u001b[38;5;241m=\u001b[39m params \u001b[38;5;241m|\u001b[39m params_iter\n\u001b[1;32m---> 20\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43muefa\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl_matches\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m data_iter \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_iter:\n",
      "File \u001b[1;32mc:\\Users\\samue\\GitHub\\uefa-euros-predictor\\.venv\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\GitHub\\uefa-euros-predictor\\.venv\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\GitHub\\uefa-euros-predictor\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\samue\\GitHub\\uefa-euros-predictor\\.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\samue\\GitHub\\uefa-euros-predictor\\.venv\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\samue\\GitHub\\uefa-euros-predictor\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samue\\GitHub\\uefa-euros-predictor\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\samue\\GitHub\\uefa-euros-predictor\\.venv\\Lib\\site-packages\\urllib3\\connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1395\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "uefa = get_uefa_config(sim_year_max, min(sim_year_mins))\n",
    "print_debug(f\"Downloading data from {uefa['url_matches']}\", 1)\n",
    "match_data = get_all_match_data(uefa)\n",
    "print_debug(\"Downloading complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.1s: ==================================================\n",
      "6.1s: Beginning Model Generation (Years 2024 - 1996)\n",
      "43.9s: Model Generation Complete (37.8s)\n",
      "43.9s: Predicting future matches\n",
      "43.9s: Predictions complete\n",
      "43.9s: Saving predictions to file\n",
      "43.9s: ==================================================\n",
      "43.9s: Beginning Model Generation (Years 2024 - 2000)\n",
      "79.1s: Model Generation Complete (35.2s)\n",
      "79.1s: Predicting future matches\n",
      "79.2s: Predictions complete\n",
      "79.2s: Saving predictions to file\n",
      "79.2s: ==================================================\n",
      "79.2s: Beginning Model Generation (Years 2024 - 2004)\n",
      "112.5s: Model Generation Complete (33.4s)\n",
      "112.5s: Predicting future matches\n",
      "112.6s: Predictions complete\n",
      "112.6s: Saving predictions to file\n",
      "112.6s: ==================================================\n",
      "112.6s: Beginning Model Generation (Years 2024 - 2008)\n",
      "143.0s: Model Generation Complete (30.4s)\n",
      "143.0s: Predicting future matches\n",
      "143.0s: Predictions complete\n",
      "143.0s: Saving predictions to file\n",
      "143.0s: ==================================================\n",
      "143.0s: Beginning Model Generation (Years 2024 - 2012)\n",
      "169.7s: Model Generation Complete (26.6s)\n",
      "169.7s: Predicting future matches\n",
      "169.7s: Predictions complete\n",
      "169.7s: Saving predictions to file\n",
      "169.7s: ==================================================\n",
      "169.7s: Beginning Model Generation (Years 2024 - 2016)\n",
      "193.8s: Model Generation Complete (24.0s)\n",
      "193.8s: Predicting future matches\n",
      "193.8s: Predictions complete\n",
      "193.8s: Saving predictions to file\n"
     ]
    }
   ],
   "source": [
    "for sim_year_min in sim_year_mins:\n",
    "    model = f\"(Years {sim_year_max} - {sim_year_min})\"\n",
    "    print_debug(f\"Beginning Model Generation {model}\", 1)\n",
    "    model_start_time = time.time()\n",
    "    match_data_filtered = get_filtered_match_data(match_data, year_min=sim_year_min)\n",
    "    params = solve_parameters(match_data_filtered)\n",
    "    model_duration = str(round(time.time() - model_start_time, 1)) + \"s\"\n",
    "    print_debug(f\"Model Generation Complete ({model_duration})\")\n",
    "\n",
    "    print_debug(\"Predicting future matches\")\n",
    "    match_data_predicted = get_predicted_match_data(match_data, params, sim_date)\n",
    "    print_debug(\"Predictions complete\")\n",
    "\n",
    "    print_debug(\"Saving predictions to file\")\n",
    "    save_predictions_to_csv(\n",
    "        match_data_predicted, sim_year_max=sim_year_max, sim_year_min=sim_year_min\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193.8s: ==================================================\n",
      "193.8s: Displaying Model Performance\n",
      "193.8s: ==================================================\n",
      "File: euros2024_predictions_model2024-1996.csv, Performance: 29, Total: 75 (38.7%)\n",
      "File: euros2024_predictions_model2024-2000.csv, Performance: 32, Total: 75 (42.7%)\n",
      "File: euros2024_predictions_model2024-2004.csv, Performance: 34, Total: 75 (45.3%)\n",
      "File: euros2024_predictions_model2024-2008.csv, Performance: 26, Total: 75 (34.7%)\n",
      "File: euros2024_predictions_model2024-2012.csv, Performance: 32, Total: 75 (42.7%)\n",
      "File: euros2024_predictions_model2024-2016.csv, Performance: 27, Total: 75 (36.0%)\n"
     ]
    }
   ],
   "source": [
    "print_debug(\"Displaying Model Performance\", 1, 1)\n",
    "display_model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_debug()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
